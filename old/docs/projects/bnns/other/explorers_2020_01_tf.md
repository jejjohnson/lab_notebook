# Explorers Group: TF 2.X and PyTorch for not so Dummies

* **Date**: Tuesday, 21 Feb 2020
* **Time**: 1600
* **Location**: IPL OE
* **Lead**: J. Emmanuel Johnson

---

### Blurb

[TensorFlow](https://www.tensorflow.org/) (TF) is one of the most popular [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) (autograd) libraries in the world right now being used in production as well as research. Backed by Google (or Alphabet, Inc.), it has a huge company support system and the open-source community is massive so there is a ton of code available for a lot of the state-of-the-art (SOTA) machine learning algorithms. A more recent autograd library, [PyTorch](https://pytorch.org/), was founded by Facebook and has risen to be the second most popular autograd library available. It's overtaken TensorFlow in the [research industry](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) because it is more Pythonic and it uses dynamic graphs which better suited the research community. TensorFlow recently got an update (TF 2.X) that has integrated keras (a high-level TF wrapper) and incorporated some more PyTorch-like design principles. So we will be going over some of the key features that you need to know to get you started on your Machine Learning and/or Deep Learning journey using TensorFlow and/or PyTorch.

---

### What To Expect

This will be fairly high level but we will have some code examples. I will be presenting an overview of the nature/status of deep learning software and then we will be going through a google colab notebook outlining some of the key features of TensorFlow and PyTorch and answering any questions people have. It should take more more than 1.5 hours. Some other things:
This will be in Python so familiarity with the language is expected and/or a strong familiarity with programming.
I expect some level of machine learning and/or deep learning background to be able to keep up with some of the terminology, e.g. optimization, loss function, etc.
This will not be a live coding session but you're more than welcome to bring your own laptops.
Even if you think this is too high-level (or low-level) but are still interested, check the resources I've listed below. There might be some useful tutorials for you.

---

### Resources

I have put the materials online. Please go through them if you get a chance. In particular I will be giving a short introduction about the nature of a deep learning library and we will spend the rest of the time walking through the key features of [this](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO#scrollTo=FjLI719fPfJi) colab notebook. The resources I've linked will be updated over the weekend and over the next few months so check back for updates if you're still interested.

* [Introduction](code/software.md "Overview of DL software in Python")
* [TensorFlow](code/tensorflow.md "Some tutorials and guides using TensorFlow")

---

### Spirit Animal

Did you know that some Koala bears carry a strand of chlamydia (Herpes)? Some [news reports](http://www.bbc.com/earth/story/20160211-half-of-australias-koalas-now-have-chlamydia) even got so far as to kill them due to potential human infections. A moment of silence for the [remaining 70% of the population](https://www.vox.com/future-perfect/2020/1/6/21051897/australia-fires-billion-animals-dead-estimate) of our moody, furry, cuddly friends as they deal with the [crazy Austrailian wildfires](https://edition.cnn.com/2020/01/01/australia/australia-fires-explainer-intl-hnk-scli/index.html).