# Blog Ideas

I would like to do some blog posts for my academic blog. There are tons of things I would like to do but I don't really have time to do it all. So I would like to try a concept: combine scientific exploration with some programming concept exploration. For example, instead of doing a segment on Object-Oriented Programming and then a separate segment on Gaussian Process regression (GPR), I would combine the two.


### Programming



### Packages

* GPyTorch - DKL, 
* Pyro
* GPFlow
* geopandas
* xarray
* 


### Algorithms

* Optimized Kernel Ridge Regression (OKRR)
  * Jax
* Optimized Kernel Entropy Components Analysis (OKECA)
  * Jax
* Rotation-Based Iterative Gaussianization (RBIG)
* Gaussian Process Regression
* Variational Gaussian Process Regression
* Variational Inference
  * Jax
  * Bayesian Neural Networks
* Deep Kernel Learning
  * GPyTorch - Gaussian Processes
  * PyTorch - Neural Networks
  * Data - Ocean Water Quality
* Gaussian Processes
  * Exact
  * Variational
  * Sparse
  * Sparse Variational
  * Deep



### Packages


* Edward2 - Bayesian Layers (the future)

### Unsorted

* Bayesian Formulas + Plotly
* OOP + GPR from Scratch
* Kernel Functions (K, GPR, KRR) + Derivatives + AutoGrad
* VI + PyTorch
* RBIG + sklearn API
* IT Measures + ESDC + RBIG
* AD + ESDC + Feature Selection
* AD + ESDC + Feature Selection (Pt II)
* HyperLabelMe + TPOT + AutoSklearn
* Flask + Xarray
* Luigi + SLURM + Experiment
* Uncertainty + GPs
* Abstract Classes + Kernel Functions

---
#### Work Deep Dive

These notebooks will be directly related to my thesis and things that I am investigating actively. They should all include some results so that I can show off some of the actual applications.

* Output Normalized Methods
  * I - Kernel Eigenmap Methods
  * II - Kernel Eigenmap Projection Methods
  * III - Manifold Alignment
  * IV - Nearest Neighbours (Annoy, KDE Trees)
  * V - Eigenvalue Decomposition Scaling (rSVD, Multigrid, Random Projections)
  * VI - Out of Sampling (Nystrom, LLL, Var. Nystrom)
* Kernel Methods
  * I - Kernel Functions
  * II - Learning with Kernel Functions (Overview of Literature)
  * III - Gradients and Sensitivity Analysis
* Gaussian Processes and Uncertainty
  * I - GPs
  * II - Sparse GPs
  * III - Uncertain GPs (Literature, NIGP, My Work)
  * IV - Variational Methods
* Deep Density Destructors
  * I - Density Estimation
  * II - RBIG
  * III - GDN

---
#### Concept Notebook

These are notebooks that I decided to investigate because either I sucked at in the beginning or it was something I needed in order to advance to the next level of whatever I was doing related to my thesis.

* Bayesian Methods
* Variational Inference
* Information Theory
* Anomaly Detection

---
#### Explorers Book

* Normalizing Flows
* Automatic Machine Learning
* Neural ODEs
* 

---
#### Lab Notebook

* Earth Science Data Cube + Xarray
  * Naive AD Detection
  * Dask
* Remote Computing

**xarray**

* Shape Files
* Region Masks
* Large Scale ML - PCA, LR, KMeans, XGBoost
* Dask
* 



**Jax**

* Kernel methods
  * kernels
  * regression - krr, rff
  * bayesian regression - gp, sgps
  * classification - svm
  * dependence estimation - hsic
  * dimension reduction - okeca)
* Gaussianization flows
