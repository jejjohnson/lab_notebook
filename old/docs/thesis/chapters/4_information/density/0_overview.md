# Overview

[blog](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)
* [VAE](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)

* Non-Invertible (VAEs)
* Invertible:
  * Inverse Sampling Theorem (Uniform and PDFs)
  * Change of Variables

---
**Core Topics**

* Parametric Gaussianization
* Deep Density Destructors
* Information Theory Measures
* Generalized Divisive Normalization


**Supplementary**

* Inverse Sampling Theorem
* Change of Variables Formula
* Entropy
* NegEntropy

**Classical**
* Parametric
* Histogram
* KDE
* kNN

**Neural Density**

* Deep Density Destructor
* Normalizing Flows
* Parametric Gaussianization
  * Original: Projection Pursuit, Gaussianization
  * Modern: Rotation-Based Iterative Gaussianization (RBIG)
  * Approx: Generalized Divisive Normalization (GDN)